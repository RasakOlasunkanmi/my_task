{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c3754d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\olasunkanmi\\Desktop\\my_task\\.allenv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… All imports successful\n"
     ]
    }
   ],
   "source": [
    "from langgraph.graph import START, END, StateGraph, MessagesState\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langchain_core.messages import HumanMessage, AIMessage, SystemMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import Image, display\n",
    "import os\n",
    "\n",
    "print(\"âœ… All imports successful\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "24ade73f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… API key loaded successfully\n"
     ]
    }
   ],
   "source": [
    "# Load environment variables\n",
    "load_dotenv()\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "if not openai_api_key:\n",
    "    raise ValueError(\"OPENAI_API_KEY not found! Please set it in your .env file.\")\n",
    "\n",
    "print(\"âœ… API key loaded successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e35937f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… LLM initialized: gpt-4o-mini\n"
     ]
    }
   ],
   "source": [
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    temperature=0.7,\n",
    "    api_key=openai_api_key\n",
    ")\n",
    "\n",
    "print(f\"âœ… LLM initialized: {llm.model_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "604aea7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Assistant node defined\n"
     ]
    }
   ],
   "source": [
    "# System prompt that defines assistant behavior\n",
    "sys_msg = SystemMessage(\n",
    "    content=\"You are a friendly assistant that answers user questions. Be helpful and concise.\"\n",
    ")\n",
    "\n",
    "def assistant(state: MessagesState) -> dict:\n",
    "    \"\"\"\n",
    "    The assistant node - processes messages and generates response.\n",
    "    \"\"\"\n",
    "    # Combine system prompt with conversation history\n",
    "    messages = [sys_msg] + state[\"messages\"]\n",
    "    \n",
    "    # Get response from LLM\n",
    "    response = llm.invoke(messages)\n",
    "    \n",
    "    # Return as state update\n",
    "    return {\"messages\": [AIMessage(content=response.content)]}\n",
    "\n",
    "print(\"âœ… Assistant node defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bdd169d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_docs(state: MessagesState):\n",
    "    query = state[\"messages\"][-1].content  # latest HumanMessage\n",
    "    docs = retriever.invoke(query)\n",
    "\n",
    "    return {\n",
    "        \"messages\": [\n",
    "            ToolMessage(\n",
    "                content=\"\\n\".join(d.page_content for d in docs),\n",
    "                name=\"retriever\"\n",
    "            )\n",
    "        ]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b07bc221",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Graph structure defined\n"
     ]
    }
   ],
   "source": [
    "# Create a StateGraph with MessagesState\n",
    "builder = StateGraph(MessagesState)\n",
    "\n",
    "# Add the assistant node\n",
    "builder.add_node(\"assistant\", assistant)\n",
    "\n",
    "# Define the flow:\n",
    "# START â†’ assistant â†’ END\n",
    "builder.add_edge(START, \"assistant\")\n",
    "builder.add_edge(\"assistant\", END)\n",
    "\n",
    "print(\"âœ… Graph structure defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bae8039e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Agent compiled with memory\n"
     ]
    }
   ],
   "source": [
    "# Create a memory checkpointer (stores in memory)\n",
    "memory = MemorySaver()\n",
    "\n",
    "# Compile the graph WITH memory\n",
    "agent = builder.compile(checkpointer=memory)\n",
    "\n",
    "print(\"âœ… Agent compiled with memory\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "61c6d595",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not display graph: Failed to reach https://mermaid.ink API while trying to render your graph after 1 retries. To resolve this issue:\n",
      "1. Check your internet connection and try again\n",
      "2. Try with higher retry settings: `draw_mermaid_png(..., max_retries=5, retry_delay=2.0)`\n",
      "3. Use the Pyppeteer rendering method which will render your graph locally in a browser: `draw_mermaid_png(..., draw_method=MermaidDrawMethod.PYPPETEER)`\n",
      "Graph structure: START â†’ assistant â†’ END\n"
     ]
    }
   ],
   "source": [
    "# Visualize the graph structure\n",
    "try:\n",
    "    display(Image(agent.get_graph().draw_mermaid_png()))\n",
    "except Exception as e:\n",
    "    print(f\"Could not display graph: {e}\")\n",
    "    print(\"Graph structure: START â†’ assistant â†’ END\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9e82d16d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting conversation with session ID: chat-session-0013\n"
     ]
    }
   ],
   "source": [
    "# Define a session ID for this conversation\n",
    "session_id = \"chat-session-0013\"\n",
    "\n",
    "print(f\"Starting conversation with session ID: {session_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c54af3a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Conversation function ready\n"
     ]
    }
   ],
   "source": [
    "def run_conversation(user_input: str, thread_id: str = session_id):\n",
    "    \"\"\"\n",
    "    Send a message to the agent and get response.\n",
    "    âš ï¸ WARNING: Using default thread_id shares conversation acrosss all calls!\n",
    "    In production, ALWAYS provide unique thread_id per user.\n",
    "    \"\"\"\n",
    "    # Invoke the agent\n",
    "    result = agent.invoke(\n",
    "        {\"messages\": [HumanMessage(content=user_input)]},\n",
    "        config={\"configurable\": {\"thread_id\": thread_id}}\n",
    "    )\n",
    "    \n",
    "    # Print the conversation\n",
    "    for message in result[\"messages\"]:\n",
    "        if isinstance(message, HumanMessage):\n",
    "            print(f\"\\nðŸ‘¤ User: {message.content}\")\n",
    "        elif isinstance(message, AIMessage):\n",
    "            print(f\"ðŸ¤– Agent: {message.content}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "\n",
    "print(\"âœ… Conversation function ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f5a641fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ‘¤ User: Hello!\n",
      "ðŸ¤– Agent: Hello! How can I assist you today?\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "run_conversation(\"Hello!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "15330fd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ‘¤ User: Hello!\n",
      "ðŸ¤– Agent: Hello! How can I assist you today?\n",
      "\n",
      "ðŸ‘¤ User: I do not have a favorite color\n",
      "ðŸ¤– Agent: That's perfectly okay! Not everyone has a favorite color. Is there a specific reason you feel that way, or do you enjoy a variety of colors?\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# First message\n",
    "run_conversation(\"I do not have a favorite color\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "50a6031f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ‘¤ User: Hello!\n",
      "ðŸ¤– Agent: Hello! How can I assist you today?\n",
      "\n",
      "ðŸ‘¤ User: I do not have a favorite color\n",
      "ðŸ¤– Agent: That's perfectly okay! Not everyone has a favorite color. Is there a specific reason you feel that way, or do you enjoy a variety of colors?\n",
      "\n",
      "ðŸ‘¤ User: What's my favorite color?\n",
      "ðŸ¤– Agent: Since you mentioned you do not have a favorite color, it seems you might not have one. But if you have any colors you like or enjoy, feel free to share!\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Follow-up question - does it remember?\n",
    "run_conversation(\"What's my favorite color?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0af0431d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ‘¤ User: What's my favorite color?\n",
      "ðŸ¤– Agent: I don't know your favorite color, but Iâ€™d love to help you figure it out! What colors do you usually like?\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "run_conversation(\"What's my favorite color?\", thread_id=\"111\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "26c0e85b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ‘¤ User: Hello!\n",
      "ðŸ¤– Agent: Hello! How can I assist you today?\n",
      "\n",
      "ðŸ‘¤ User: I do not have a favorite color\n",
      "ðŸ¤– Agent: That's perfectly okay! Not everyone has a favorite color. Is there a specific reason you feel that way, or do you enjoy a variety of colors?\n",
      "\n",
      "ðŸ‘¤ User: What's my favorite color?\n",
      "ðŸ¤– Agent: Since you mentioned you do not have a favorite color, it seems you might not have one. But if you have any colors you like or enjoy, feel free to share!\n",
      "\n",
      "ðŸ‘¤ User: I'm learning about RAG systems\n",
      "ðŸ¤– Agent: That's great! RAG (Retrieval-Augmented Generation) systems combine retrieval-based methods and generative models to improve the quality of responses, especially in tasks like question answering or conversational AI. They retrieve relevant information from a knowledge base or database and then generate responses using that information. \n",
      "\n",
      "If you have specific questions or need clarification on certain aspects of RAG systems, feel free to ask!\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Start a new topic\n",
    "run_conversation(\"I'm learning about RAG systems\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "559feb68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ‘¤ User: Hello!\n",
      "ðŸ¤– Agent: Hello! How can I assist you today?\n",
      "\n",
      "ðŸ‘¤ User: I do not have a favorite color\n",
      "ðŸ¤– Agent: That's perfectly okay! Not everyone has a favorite color. Is there a specific reason you feel that way, or do you enjoy a variety of colors?\n",
      "\n",
      "ðŸ‘¤ User: What's my favorite color?\n",
      "ðŸ¤– Agent: Since you mentioned you do not have a favorite color, it seems you might not have one. But if you have any colors you like or enjoy, feel free to share!\n",
      "\n",
      "ðŸ‘¤ User: I'm learning about RAG systems\n",
      "ðŸ¤– Agent: That's great! RAG (Retrieval-Augmented Generation) systems combine retrieval-based methods and generative models to improve the quality of responses, especially in tasks like question answering or conversational AI. They retrieve relevant information from a knowledge base or database and then generate responses using that information. \n",
      "\n",
      "If you have specific questions or need clarification on certain aspects of RAG systems, feel free to ask!\n",
      "\n",
      "ðŸ‘¤ User: Can you explain the main components?\n",
      "ðŸ¤– Agent: Sure! The main components of a Retrieval-Augmented Generation (RAG) system typically include:\n",
      "\n",
      "1. **Retrieval Component**: \n",
      "   - This part is responsible for fetching relevant information from a database or knowledge base. It uses techniques like vector similarity search or traditional search methods to find documents or snippets that are pertinent to the input query.\n",
      "\n",
      "2. **Generator Component**: \n",
      "   - After retrieval, the generator takes the retrieved information along with the original query to produce a coherent and contextually relevant response. This component is usually based on a generative model, like GPT or T5.\n",
      "\n",
      "3. **Knowledge Base**: \n",
      "   - A structured or unstructured collection of documents, texts, or data that the retrieval component searches through. It can be a large corpus of text, a database, or any other source of factual information.\n",
      "\n",
      "4. **Integration Mechanism**: \n",
      "   - This component combines the outputs of the retrieval and generation processes. It may involve techniques to ensure that the generated response is well-informed by the retrieved content.\n",
      "\n",
      "5. **Training Mechanism**: \n",
      "   - RAG systems often require a training process where both components are fine-tuned together. This can involve using datasets that include questions and their answers, ensuring that the generator learns to produce responses based on the retrieved contexts.\n",
      "\n",
      "If you have more specific aspects youâ€™d like to know about, just let me know!\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Reference it\n",
    "run_conversation(\"Can you explain the main components?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e0874a76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ‘¤ User: Hello!\n",
      "ðŸ¤– Agent: Hello! How can I assist you today?\n",
      "\n",
      "ðŸ‘¤ User: I do not have a favorite color\n",
      "ðŸ¤– Agent: That's perfectly okay! Not everyone has a favorite color. Is there a specific reason you feel that way, or do you enjoy a variety of colors?\n",
      "\n",
      "ðŸ‘¤ User: What's my favorite color?\n",
      "ðŸ¤– Agent: Since you mentioned you do not have a favorite color, it seems you might not have one. But if you have any colors you like or enjoy, feel free to share!\n",
      "\n",
      "ðŸ‘¤ User: I'm learning about RAG systems\n",
      "ðŸ¤– Agent: That's great! RAG (Retrieval-Augmented Generation) systems combine retrieval-based methods and generative models to improve the quality of responses, especially in tasks like question answering or conversational AI. They retrieve relevant information from a knowledge base or database and then generate responses using that information. \n",
      "\n",
      "If you have specific questions or need clarification on certain aspects of RAG systems, feel free to ask!\n",
      "\n",
      "ðŸ‘¤ User: Can you explain the main components?\n",
      "ðŸ¤– Agent: Sure! The main components of a Retrieval-Augmented Generation (RAG) system typically include:\n",
      "\n",
      "1. **Retrieval Component**: \n",
      "   - This part is responsible for fetching relevant information from a database or knowledge base. It uses techniques like vector similarity search or traditional search methods to find documents or snippets that are pertinent to the input query.\n",
      "\n",
      "2. **Generator Component**: \n",
      "   - After retrieval, the generator takes the retrieved information along with the original query to produce a coherent and contextually relevant response. This component is usually based on a generative model, like GPT or T5.\n",
      "\n",
      "3. **Knowledge Base**: \n",
      "   - A structured or unstructured collection of documents, texts, or data that the retrieval component searches through. It can be a large corpus of text, a database, or any other source of factual information.\n",
      "\n",
      "4. **Integration Mechanism**: \n",
      "   - This component combines the outputs of the retrieval and generation processes. It may involve techniques to ensure that the generated response is well-informed by the retrieved content.\n",
      "\n",
      "5. **Training Mechanism**: \n",
      "   - RAG systems often require a training process where both components are fine-tuned together. This can involve using datasets that include questions and their answers, ensuring that the generator learns to produce responses based on the retrieved contexts.\n",
      "\n",
      "If you have more specific aspects youâ€™d like to know about, just let me know!\n",
      "\n",
      "ðŸ‘¤ User: Which component is most important?\n",
      "ðŸ¤– Agent: The importance of each component in a Retrieval-Augmented Generation (RAG) system can vary depending on the specific use case and context, but generally:\n",
      "\n",
      "1. **Retrieval Component**: \n",
      "   - This is crucial for providing relevant and accurate information. If the retrieval component fails to fetch appropriate documents or snippets, the generative model may produce responses that are irrelevant or incorrect.\n",
      "\n",
      "2. **Generator Component**: \n",
      "   - The quality of the generated response largely depends on the generative model. A strong generator can effectively synthesize information and produce coherent, contextually appropriate answers, even if the retrieved content is not perfect.\n",
      "\n",
      "In many cases, the **retrieval component** is often viewed as the most critical because it directly influences the quality and relevance of the information that the generator relies on. However, both components are interdependent; a well-functioning retrieval system is essential for a generative model to produce high-quality outputs.\n",
      "\n",
      "Ultimately, the best results come from a balanced optimization of both components within the RAG system.\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Follow-up question\n",
    "run_conversation(\"Which component is most important?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0712fb63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ”µ CONVERSATION 1\n",
      "\n",
      "ðŸ‘¤ User: My name is Alice\n",
      "ðŸ¤– Agent: Hi Alice! How can I assist you today?\n",
      "\n",
      "======================================================================\n",
      "\n",
      "ðŸŸ¢ CONVERSATION 2\n",
      "\n",
      "ðŸ‘¤ User: My name is Bob\n",
      "ðŸ¤– Agent: Nice to meet you, Bob! How can I assist you today?\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Conversation 1\n",
    "print(\"\\nðŸ”µ CONVERSATION 1\")\n",
    "run_conversation(\"My name is Alice\", thread_id=\"user_alicee\")\n",
    "\n",
    "# Conversation 2 (different user)\n",
    "print(\"\\nðŸŸ¢ CONVERSATION 2\")\n",
    "run_conversation(\"My name is Bob\", thread_id=\"user_bobb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "66cf0d82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ”µ BACK TO CONVERSATION 1\n",
      "\n",
      "ðŸ‘¤ User: My name is Alice\n",
      "ðŸ¤– Agent: Hi Alice! How can I assist you today?\n",
      "\n",
      "ðŸ‘¤ User: What's my name?\n",
      "ðŸ¤– Agent: Your name is Alice! How can I help you today?\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Back to Alice - does it remember her name?\n",
    "print(\"\\nðŸ”µ BACK TO CONVERSATION 1\")\n",
    "run_conversation(\"What's my name?\", thread_id=\"user_alicee\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2397f487",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸŸ¢ BACK TO CONVERSATION 2\n",
      "\n",
      "ðŸ‘¤ User: My name is Bob\n",
      "ðŸ¤– Agent: Nice to meet you, Bob! How can I assist you today?\n",
      "\n",
      "ðŸ‘¤ User: What's my name?\n",
      "ðŸ¤– Agent: Your name is Bob. How can I help you further?\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Back to Bob\n",
    "print(\"\\nðŸŸ¢ BACK TO CONVERSATION 2\")\n",
    "run_conversation(\"What's my name?\", thread_id=\"user_bobb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d5ccf56c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "ðŸ¤– Interactive Chat Started\n",
      "Type your message and press Enter. Type 'exit' to quit.\n",
      "======================================================================\n",
      "\n",
      "\n",
      "ðŸ‘‹ Goodbye!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def interactive_chat():\n",
    "    \"\"\"\n",
    "    Run an interactive chat session.\n",
    "    Type 'exit' or 'quit' to stop.\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"ðŸ¤– Interactive Chat Started\")\n",
    "    print(\"Type your message and press Enter. Type 'exit' to quit.\")\n",
    "    print(\"=\"*70 + \"\\n\")\n",
    "    \n",
    "    thread_id = \"interactive_session2\"\n",
    "    \n",
    "    while True:\n",
    "        user_input = input(\"\\nðŸ‘¤ You: \").strip()\n",
    "        \n",
    "        if user_input.lower() in [\"exit\", \"quit\"]:\n",
    "            print(\"\\nðŸ‘‹ Goodbye!\\n\")\n",
    "            break\n",
    "        \n",
    "        if not user_input:\n",
    "            continue\n",
    "        \n",
    "        # Get response\n",
    "        result = agent.invoke(\n",
    "            {\"messages\": [HumanMessage(content=user_input)]},\n",
    "            config={\"configurable\": {\"thread_id\": thread_id}}\n",
    "        )\n",
    "        \n",
    "        # Print agent's response\n",
    "        agent_message = result[\"messages\"][-1]\n",
    "        print(f\"\\nðŸ¤– Agent: {agent_message.content}\")\n",
    "\n",
    "# Uncomment to run interactive chat:\n",
    "interactive_chat()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c7da37e",
   "metadata": {},
   "source": [
    "### Topic 2 - Tool Integration for Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c3af60d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… All imports successful\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "from langgraph.graph import START, END, StateGraph, MessagesState\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langchain_core.messages import HumanMessage, AIMessage, SystemMessage, ToolMessage\n",
    "from langchain_core.tools import tool\n",
    "from langchain_openai import ChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import Image, display\n",
    "from typing import Literal\n",
    "import os\n",
    "\n",
    "print(\"âœ… All imports successful\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "abb4c127",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… API key loaded\n"
     ]
    }
   ],
   "source": [
    "# Load API key\n",
    "load_dotenv()\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "if not openai_api_key:\n",
    "    raise ValueError(\"OPENAI_API_KEY not found! Please set it in your .env file.\")\n",
    "\n",
    "print(\"âœ… API key loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5f95ef48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… LLM initialized: gpt-4o-mini\n"
     ]
    }
   ],
   "source": [
    "# Initialize LLM\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    temperature=0,  # Lower temperature for more precise tool usage\n",
    "    api_key=openai_api_key\n",
    ")\n",
    "\n",
    "print(f\"âœ… LLM initialized: {llm.model_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f5d72323",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Calculator tool created\n"
     ]
    }
   ],
   "source": [
    "@tool\n",
    "def calculator(expression: str) -> str:\n",
    "    \"\"\"\n",
    "    Evaluate a mathematical expression and return the result.\n",
    "    Use this tool when you need to perform calculations.\n",
    "    \n",
    "    Args:\n",
    "        expression: A mathematical expression like \"2 + 2\" or \"15 * 37\"\n",
    "        \n",
    "    Returns:\n",
    "        The calculated result as a string\n",
    "        \n",
    "    Examples:\n",
    "        - \"2 + 2\" returns \"4\"\n",
    "        - \"100 / 5\" returns \"20.0\"\n",
    "        - \"2 ** 10\" returns \"1024\"\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Evaluate the expression safely\n",
    "        result = eval(expression, {\"__builtins__\": {}}, {})\n",
    "        return str(result)\n",
    "    except Exception as e:\n",
    "        return f\"Error calculating: {str(e)}\"\n",
    "\n",
    "print(\"âœ… Calculator tool created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "accc0ed8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123 * 456 = 56088\n",
      "2^10 = 1024\n"
     ]
    }
   ],
   "source": [
    "# Test the calculator tool\n",
    "result = calculator.invoke({\"expression\": \"123 * 456\"})\n",
    "print(f\"123 * 456 = {result}\")\n",
    "\n",
    "result2 = calculator.invoke(\"2 ** 10\")\n",
    "print(f\"2^10 = {result2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a41fea5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Text analyzer tool created\n"
     ]
    }
   ],
   "source": [
    "@tool\n",
    "def text_analyzer(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Analyze text and return statistics about it.\n",
    "    Use this tool when you need to analyze or count things in text.\n",
    "    \n",
    "    Args:\n",
    "        text: The text to analyze\n",
    "        \n",
    "    Returns:\n",
    "        Statistics about the text (characters, words, sentences)\n",
    "        \n",
    "    Examples:\n",
    "        - \"Hello world\" returns character count, word count, etc.\n",
    "    \"\"\"\n",
    "    char_count = len(text)\n",
    "    word_count = len(text.split())\n",
    "    sentence_count = text.count('.') + text.count('!') + text.count('?')\n",
    "    \n",
    "    return f\"\"\"Text Analysis:\n",
    "- Characters: {char_count}\n",
    "- Words: {word_count}\n",
    "- Sentences: {sentence_count}\n",
    "- First 50 chars: {text[:50]}...\"\"\"\n",
    "\n",
    "print(\"âœ… Text analyzer tool created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ff60506a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text Analysis:\n",
      "- Characters: 41\n",
      "- Words: 9\n",
      "- Sentences: 3\n",
      "- First 50 chars: Hello! This is a test. How are you today?...\n"
     ]
    }
   ],
   "source": [
    "# Test the text analyzer\n",
    "test_text = \"Hello! This is a test. How are you today?\"\n",
    "result = text_analyzer.invoke({\"text\": test_text})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "505c5794",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… LLM bound to 2 tools\n",
      "   Tools: ['calculator', 'text_analyzer']\n"
     ]
    }
   ],
   "source": [
    "# Create a list of tools\n",
    "tools = [calculator, text_analyzer]\n",
    "\n",
    "# Bind tools to the LLM\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "print(f\"âœ… LLM bound to {len(tools)} tools\")\n",
    "print(f\"   Tools: {[tool.name for tool in tools]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8e02c3f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response type: <class 'langchain_core.messages.ai.AIMessage'>\n",
      "\n",
      "Content: \n",
      "\n",
      "Tool calls: [{'name': 'calculator', 'args': {'expression': '234 * 567'}, 'id': 'call_ZNJRGZADPaPi8EhPWlhXG4dZ', 'type': 'tool_call'}]\n"
     ]
    }
   ],
   "source": [
    "# Test: Does LLM decide to call calculator?\n",
    "response = llm_with_tools.invoke([HumanMessage(content=\"What is 234 * 567?\")])\n",
    "\n",
    "print(f\"Response type: {type(response)}\")\n",
    "print(f\"\\nContent: {response.content}\")\n",
    "print(f\"\\nTool calls: {response.tool_calls}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2c695fe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Content: Hello! I'm just a program, so I don't have feelings, but I'm here and ready to help you. How can I assist you today?\n",
      "Tool calls: []\n"
     ]
    }
   ],
   "source": [
    "# Test: Does LLM decide NOT to call tools for simple queries?\n",
    "response2 = llm_with_tools.invoke([HumanMessage(content=\"Hello! How are you?\")])\n",
    "\n",
    "print(f\"Content: {response2.content}\")\n",
    "print(f\"Tool calls: {response2.tool_calls}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "237bb3e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Assistant node defined\n"
     ]
    }
   ],
   "source": [
    "# System prompt that encourages tool usage\n",
    "sys_msg = SystemMessage(content=\"\"\"You are a helpful assistant with access to tools.\n",
    "\n",
    "When asked to perform calculations, use the calculator tool.\n",
    "When asked to analyze text, use the text_analyzer tool.\n",
    "\n",
    "Only use tools when necessary - for simple questions, answer directly.\"\"\")\n",
    "\n",
    "def assistant(state: MessagesState) -> dict:\n",
    "    \"\"\"\n",
    "    Assistant node - decides whether to use tools or answer directly.\n",
    "    \"\"\"\n",
    "    messages = [sys_msg] + state[\"messages\"]\n",
    "    response = llm_with_tools.invoke(messages)\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "print(\"âœ… Assistant node defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "16af4181",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Conditional routing function defined\n"
     ]
    }
   ],
   "source": [
    "def should_continue(state: MessagesState) -> Literal[\"tools\", \"__end__\"]:\n",
    "    \"\"\"\n",
    "    Decide next step based on last message.\n",
    "    \n",
    "    If LLM called a tool â†’ go to 'tools' node\n",
    "    If LLM provided final answer â†’ go to END\n",
    "    \"\"\"\n",
    "    last_message = state[\"messages\"][-1]\n",
    "    \n",
    "    # Check if LLM made tool calls\n",
    "    if last_message.tool_calls:\n",
    "        return \"tools\"\n",
    "    \n",
    "    # No tool calls - we're done\n",
    "    return \"__end__\"\n",
    "\n",
    "print(\"âœ… Conditional routing function defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5ce0d73b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Agent graph compiled with tools and memory\n"
     ]
    }
   ],
   "source": [
    "# Create the graph\n",
    "builder = StateGraph(MessagesState)\n",
    "\n",
    "# Add nodes\n",
    "builder.add_node(\"assistant\", assistant)\n",
    "builder.add_node(\"tools\", ToolNode(tools))  # ToolNode executes tool calls automatically\n",
    "\n",
    "# Define edges\n",
    "builder.add_edge(START, \"assistant\")\n",
    "builder.add_conditional_edges(\n",
    "    \"assistant\",\n",
    "    should_continue,\n",
    "    {\"tools\": \"tools\", \"__end__\": END}\n",
    ")\n",
    "builder.add_edge(\"tools\", \"assistant\")  # After tools, go back to assistant\n",
    "\n",
    "# Add memory\n",
    "memory = MemorySaver()\n",
    "agent = builder.compile(checkpointer=memory)\n",
    "\n",
    "print(\"âœ… Agent graph compiled with tools and memory\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "16110351",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAANgAAAD5CAIAAADKsmwpAAAQAElEQVR4nOydB3wURfvHZ/dKLrkU0ntIQgkklIgUQV5AiuCfIthQOoi0FwQBRQWkigIqvEgTERFpIr1JUYq0IEVKQAKBBEJIJ71d2f0/u5scB7kLHLKbuex8P+HYm53dvdv93cw8z8w8o2RZFhEIVY0SEQgYQIRIwAIiRAIWECESsIAIkYAFRIgELCBCfJT0O7qrp3Oz0/UlRUajgTHqHtpL0Qj8XRSFWKY8iUaI36YUCPaxDMVtU+iBWwwSKBaxkGR2HgVijZANDqAeSUQ0y+U0pQuHM/APUch0IbMPAE/RgVI50I7OysBwTZMONZAdQhE/okDS9dITOzKyUksYBmmcaKWaVqlpWoEMpYx5NormtWMmRC6F4e4hpaB4IfKpNIWY8htLCW+RmTa5zKyRFV4fTaQ52SLT+UGtoHXzbHA2xJoLEVTIGJFex5QWMXoDq9bQAWGabkP9kf1AhAhFoH7Hiru6YqOnnyaqpWvD1q7IrmHQ4c2Zt2ILoET3C9G8/n4gsgfkLsRfF95LSyoKiXDuMcwPVS+yUgy7f7hbnGds95ZfvaZahDeyFuL3kxPUKmrg9FBUfbl6quDP7elBdZ26vYv1L02+Qlw55VZgLe0rg32RDFg5NbFZR/fGbd0QrshUiN99fLNWY9eO73gj2bBySqJPkEOPEZhaMDSSH6umJdasp5WVCoGhs0PTkkqObctCWCI7Ie78LgV8gV0GVTfT5El4b1bYpePZCEtkJkQjunO9cPC0UCRPaBQSoV09IxHhh7yEuOaLO95BjkjGdB/mX1xovH6uEGGGvISYd1/Xe6x9OHjFw6+m5tiOdIQZMhLirhUpTlqlxN/4448/3rFjB7KdTp06JScnIxHo/l5gcYERYYaMhJh6u6RmlNQdDFevXkW2k5KSkp0tllWhVCO1RnFoQwbCCRkJUVfCPP+SBxKHEydODB8+vHXr1j179pw2bVpmZiYkNm3a9N69e7NmzWrXrh28LSgoWL58+cCBA4VsCxYsKCkpEQ7v0KHDhg0b3nvvPTjk6NGj3bt3h8RXX311woQJSATcfdTJCUUIJ+QixJuXimka1fBVIBG4du3a2LFjmzVrtnnz5o8++uj69evTp09HvDrhderUqUeOHIGNjRs3rl69un///gsXLoT8Bw8eXLFihXAGlUq1bdu2iIiIJUuWvPjii5ABEqFO//rrr5EI+NbUlBbi1ZEhl/GIKQlFChWFxOHChQsajWbIkCE0Tfv5+UVGRsbHx1fM1q9fPyj5wsLChLcXL148efLk+++/j/ixXm5ubhMnTkSS4BesuRqTi3BCLkIsKWAUCrGEGB0dDZXsuHHjWrRo0aZNm+DgYKhhK2aDYu/UqVNQcUORaTAYIMXD40FTAeSLpMLdW8UYGIQTcqmaGZZhROtVr1ev3qJFi7y9vb/99ttevXqNGjUKSruK2WAv1MWQYfv27WfPnh08eLD5XrVajSRDqeAGkeOEXIToqFWwYhYBrVq1grbgrl27oHWYm5sLpaNQ5plgWXbLli29e/cGIUL1DSn5+fmoishJLyFCrBp8Ah2NBrFKxHPnzkFrDzagUOzWrRuYuiAycMGY59Hr9cXFxT4+PsJbnU73559/oioiPamUxqxRJhchRjTXghBLi0XRIlTEYCxv3boVnH+xsbFgHYMi/f39HRwcQHkxMTFQEYMdExoaunPnzrt37+bk5MycORNalnl5eYWFFnrbICe8glkNZ0MikJZQonESxYHw1MjIj6hQUjF7RRkEBeYwVLhfffUVdIcMGzZMq9VCW1Cp5MocMKXPnDkDZSQUh3PmzAHj+o033gAnYvPmzUePHg1vO3bsCL7GR04YFBQErkRwOkKzEonA/YxS3yANwgkZDYzdOD+pMN/w7swwJHuWTIgfMr2WowtGzUQZlYidB/hj2McqPXtWpYBLFSsVIllNsHf3VTo40tuX3us5KsBiBqPRCA5ni7vAtgAvIGXJ0gwPD1+1ahUSh9U8Fnc5OztDn6HFXVFRUdBDg6yQeLXw+fZidXU+NfKas5J8s3T70qT/fl3bWoaKzTUBeOTw4C3ugragyRZ+5uTzWNwFLnRoYlrcBb8ZsJYs7jqwLj0hNn/4F7UQZshu8tS6L+8wRrb/5JpIliweH//aqJCA2hI6z58M2c1Z6ftxSFGB8cyBHCQ/Vs9IrBnhjKEKkTxn8Q3/IvyvA5l5GfKqCtbPvQs2SvfhmM4ak+8E+yUTb3bq7Ve3Ge6xOJ4JP8264xmgxjnYg6xDjiydeNO/pmOvMQGoWvPD1ASNs7LvpGCEMXIPwvTDZwkGHduii2d0O3zDcTw125elJN8sqtPY5eX+Ytn1zwoSlg6d2Jl16XgOTaPgCG3nvn4KHJvythF/ofDs7/ezUkpd3FUDPq5pF85iIsQyjm7NuH4uv6TIqFTRWlelRqtwdlPRCkave3B/FArKWB4wkxKivfJROkHELCoL12m+jYQIs0zZKxzDZWfKjkV8/E7WFL/TFHmW3+AOQWXhQE2xQGkFBb4ns5xl6UoVpFNFuYaCfENJoRGOcvNStX3NO6iu3UziJkJ8lJM7s+4lFBdkG4wGZGRY88FjZaGFy95w8YOFEMV8PGNWCDbMd74wLGtyR7C8aPls/AFGI8NFfOXkxmVmuNjF/IGgKUo4ihW6cPhHw/flUOUn50/34G155GOlCv5otYZ28VBFRLtENHdG9gYRotSMGTOmT58+LVu2RAQzSDB3qTEYDMIIMYI55I5IDRGiRcgdkRoiRIuQOyI1er1epVIhwsMQIUoNKREtQu6I1BAhWoTcEakhQrQIuSNSA0IkbcSKECFKDSkRLULuiNQQIVqE3BGpIUK0CLkjUkOEaBFyR6QGHNpEiBUhd0RSuIXFGUahwCsAEg4QIUoKqZetQW6KpBAhWoPcFEkhIx6sQYQoKaREtAa5KZJChGgNclMkhQjRGuSmSAoRojXITZEUYqxYgwhRUkiJaA1yU6TGWixXmUOEKCnQuZeamooIFSBClBSolx9ZGo0gQIQoKUSI1iBClBQiRGsQIUoKEaI1iBAlhQjRGkSIkkKEaA0iREkhQrQGEaKkECFagwhRUkCIRiNZIdUCclx5qmqBzhWixYoQIUoNqZ0tQoQoNUSIFiFtRKkhQrQIEaLUECFahAhRaogQLUKEKDVEiBYhK09JRHR0NE2XmYZwz2EbXrt16zZz5kxEIFazZDRq1AhxS0ZygCuRoih/f/9+/fohAg8RokQMGDBAq9WapzRu3Lhu3bqIwEOEKBEdO3Y0l52np+c777yDCOUQIUrHoEGDXF1dhe169eo1bNgQEcohQpSO//znPxEREbDh5ubWt29fRDBDdlZz7ImClMTCkqKyYQflK8xzS3ILy8UjzqSgEM0yBmEbMcJy8UoKGR/cLUiHbAYDa55HoaC5dcFNh1BlmU1H5eXlXLx0ycXZFYxoIQfFrQL+IINCiYyG8hXvuRMiYYCEsPS4QkkbDYzpuyiUlGldc5qimPKzwAdj2Qcf1XQ2pUKh0SqatPNy80W4ISMhJsfr9qxKRgyrdKBLi8oep/CQOOmwwurwZYnccvOCVstWjUe0gmUYyjwPt/688cFJkGmJ+/JDWKpsdXqzo+Ak/Jr2Qjq/pv1DGfgzmJ2QYY206WNQCpY1UqZvRCvKPgD/hkUM9eBLwX8mxdJl27SCUqgoQwnjVEM1YHIwwgm5CDElQbdj2d3o9p5RLd2Q7Nm9IsWg1/f/NARhgzyEaETLPrnZb3ItRChn34/3Sgr1/SfXRHggC2Nl86JkN08NIpjRZXBAYZ4xNVGH8EAWQsy5r/cLIUJ8FLUDfflELsIDWQx60JcYEQlKWAEDwxbm41IiykKIRoZlyDSRCjB6FmFzV8gwMAIWECESsEAWQuTcxxSFCA8D/UkUNosCykKILNeHRsb/VoBl8LkrpGqWLyx0QDIIE2QhRIWCopVknBHWyMN9Y2QZAza/fWygFSyNzfMnVbN8YYwUg810QrkIsXzYFQFT5OK+IVSE92ohTJCN+wYR940lsBGiPGzJqnNo37oV/1KHppcu/Y3wg2HLpjTggCyESFddG7FGDfcB/Yf6+PhVkich4ebbfbqhf0ev1zvdS0m26RAKowJRHlUz99Nnq+a37+HhOXjQiMrzxF2/iv4dqakpOTnZyJ6Rh7Fie4l46tSxQ4f3X7r8d15ebv16Dfr3H/pcdFNhV8zpE7/8suZa3BUPD68GDRoPGzrG09PLWjpUze++9/b/FnzfqNFz+QX5P65efjrmeHbO/Yi6kR07vtL1/3pCypqfV8LhUIOPGvnBm2/0tXbpbds3/bx25cJvVkyb8VFi4q3w8NqQuUvn7n9fODt+Aqf1vv1ehdL3sbp/cFsofpoYHsimjWhL9pKSks+/mFJaWvrxpBlzPl8YEhI6ecoH9+9nwa7rN6598unY555rtnrV5vfHfHTz5vW586ZXkm7OvHkzrl65NG7cJ5Cnfv0GCxZ+ceXKJdDN270H+Pr6Hf7jLAirkkurVKqCgvxF3877cMLUQ7+fadum47z5M9PSUkGmX3y+EDKsW7vjyVX4FLdFVORiNTO2WM0ajWblio2Ojo5ubjXgLRRLO3Zuvhx7oW2bDrGXL8Defn2H0DQN6qkXEXkrIR7yWEs35+Kl86C5Zk1fgO1h741p27ajm2uNJ780vNXr9QMHDIuM5EJEdH65G5Sm8fFxcDn0VEBrBR9jRR5VMzcZ3rayv6iocOUPiy9cPJeVlSmkCI2wBg2jodD6ZPK4ps+3aNmyTVBgsFBvWks3p2HD6E2/rs3NzWncqEmzZi0j6ta36dIC9epFCRsuLlz0EigjUbVAHlUz99O34bcP9d3YD4ZC8TN18pwD+04d3B9j2lW3Tr0vv1jk5em94vtv+w/oNfHDUbGxFytJN2fSR9PfeL3PmbOnJk8d/9rrnVb9uKxixM5KLi1QXQdWyqNqRrZx5OhBnU4HrTSoItHDBRLQonkr+IPW2Llzp7ds3fDp5HFbtxxUKpUW080PdHVxhbq7b5/BoNFjxw//vPYHZ2eXt97s9+SXfrZQOPlvZCFEqJYVthQkYK5CxSdIATj65x+mXRcunCvVlYLgvLy8O3fu5ucXMG78sNS0lMyMdIvppgNz83L/+GPf/73yKrQCoY6GP2jegYnz5JcWA3yKV1lUzVAtG20ZixweXgfaZzt3bYGq8/RfJ8+f/wtMh/T0VNgVe+Xi9Bkf7dq9Fcqqq//Ebt22EZTn5+tvLd10TqVC+dOaFdNnToLiEKzgAwf23Ii/1rABF4opKCgELnf8+JGkpNuVXLoSgkNC4fXIkYN37iSiJ4br+STGipTQNKWw5SfXoX3n27dvrfn5e/CwgJELbbuNv6xZv2F1fn7e6P9OBKktXvLVNwvmqNXq9i91XvDNCqiXoYa1mG46p1arnTl9/rdL5o8Z+y68DQurNWL4uFe69IDt4FfSDQAAEABJREFUF1q0BkVOnTYRLOJBA4dZu3RdK8YNEBgQBA5FMKLBEho5YhyyQ2QR+2bxhPh6zV1bdPFBBDPWzbnlF+LQ87+BCAPILD75wt0SbJpm8hgYyyIyCswCNEa/T7k4tPmYsISHYI3wh8sPVB5+RBsd2gTpkUfVTHEhphEBY2Qz6IFEeqgAVsPAZCFEpZKyddCDHCAObakxGFjSRqwIXyISq1lCoGeFxqcSwga+RCRWs4RA7xGDTyWEDaSNKDksmWNvAdJGlBouIiVRIt7IYzopIyw8RsAXWQhRrabUarK+xaOoNbSDFhcByEOIjqrcNFwWFMEHo4H18FYjPJCFUyMsyin1bjEimJF2Wwfu1RZd3REeyEKIbV/3UqnpHUvvIkI5f6xLbtjKA2GDjNZr3rzgbl6OMbiOi1eg2mjFb8Gtr8xaTqfNItuVLcjMWpoFVzGxQgr18PBIbulwGlU4u4Wcgh+KfeSjmp2fsjjwkrsAlwO8hsZSKul6YUZyUY/hgQFhDggb5LWC/YG16UnXiww6Rlf6iBDLHia3oDwXbN/C4xTWkC/bLjsAEijzFIuZK8q7wvlZ/rqmYx88FFNOqrKhveUfnr9S+YWpir8A6G+HmsHRRQVVREiEI8IJeQnRIgsWLIDXDz74AEnC2LFje/fu3apVKyQCmzZtgq+jUqm0Wq23t3doaGh0dHR9HoQ3shbi5cuXGzZseOXKlaioKCQVs2bN6tGjR+PGjZE4gMpv3LhB07QwzgPKVzc3NxcXlx07diCMkelQAPj5jRo1KjWVmy8spQqBqVOniqdCoGvXrhoNtzg1zQNCzMvLS0pKQngjxxIxKysLHk98fHzz5s2R5ID63d3dHRzEMhSKi4v79++fmJhoSnFycvrzzz8R3sirRCwtLR0+fDg8Kg8PjypRITBp0iT4DSDRcHR07NSpk6lvHSro2bNnI+yRlxD37NkzbNiwoKAgVHX4+vpCEYXE5LXXXvPz44ImggrPnz+/ffv2ZcuWIbyRhRBzc3MnTpyI+Cf0/PPPoypl3rx5YWFhSEzAXm7Xrh1sBAQEwOs333yjVqvHjBmDMEYWQpw5c+a7776L8CA5ObliWMRnzoQJE6Alunv3buEtfP0+ffq0b9/+7l1Mu5eqs7ECZsGRI0fefvtthBPgu1m+fLlQVkkMmM8DBgwYOXJk586dEWZU2xKxqKho6NChbdq0QZgBrTdT+EOJcXV1hfYiWNCCDx8rqmGJmJKSkp+fHxgYCL0LiGCJ9evXHzp0aOXKlQgbqluJ+M8//wh2MbYqvHPnTpXPbYX2ItguLVu2vH79OsKD6iPEe/fuId5TuGvXLrH9I/+Gfv36lZSUoKoGenegjp4+fTpU1ggDqokQQXzTpk2DDejjR3gDZgo4UxAGqFQqqKNjY2M///xzVNXYfRsxJyenRo0aW7duBR8hIjwV27Zt27x585o1axQKBaoi7FuI33//Pdy7IUOGIPvh9u3bNWvWRJgRFxc3cODA7777TtQBGZVgr1UztAWzsrKg1W9fKoTWYd++fRF+RERExMTELFq0aMOGDagqsEshrlixAmxPqJGHDx+O7Aqof8LDwxGu/PDDD2DzTZkyBUmO/Qlx79698FqnTp0qbNA8NeDKhqYYwhjoG2zdujU0uMEXiyTEntqI8Aihhyo3N9fNzQ3ZJ0ajEfztVTv850mACgeajF9++WWLFi2QJNhNiThp0iRh4LH9qhDIyMgYMcKWJZWriJCQkMOHD8Mvf9WqVUgS7ECIJ06cgNfx48e/9dZbyM6hKApDk9kaS5YsAaMQKmskPlgL0WAw9OjRQxhV7+vri+wf+BbwdJH9MHLkSHgEXbp0SU9PR2KCbxsxNTUVeiDA31ElI6ZEQqfTZWZm2t03gs8MrfO5c+c2bNgQiQOmJSJ0PV2+fNnDw6M6qRDxM5ugK9LuOhG8vLzAWQFexrS0NCQOmAoRikOwjlG1AyytpUuXQs+4PQaXv3DhgngNJBLpoWpISkqiaTowEIuVQZ+EGzdufPbZZ+L1u2BaIhp5UPUlODh41KhRhYWFyE4AIUInAhINTIUI9de6detQtWbHjh1xcXEFBQXIHrh582bt2rWRaGAqRPECIWBFkyZNkpOTT548ibAHSkRRhYhp6OJhw4YheRAREfH+++83atTI2dkZYUx8fLwcS8Rq30Y0B9wieXl52M44RnyEAuhi8fHxQaKBqRChl3P58uVINoC7NDs7u6rGAj4WsYtDhHMbUW5L9ECnxb1798DjjfBDAiESPyJeFBUVXbt2DYwYhBOzZ89u0KBBz549kWiQNiJeODk5aTSaOXPmIJyAElFUJyLCVojbtm2bP38+kiWRkZH16tVDOCHfNqJarZbzMo7C1NidO3ciDIDeSG9vb7E9u5gKsUePHpMmTULyBswXIaxj1SJ2554ApkJkGEaCIIKYExYWNmjQIFTVSFAvI2yFePDgQSGEiMwBWxWVrwRTVchaiCqViqZluvRGRaBcrMIpV9JUzcSPaB/k5+e7uLhAc0Wp5IYHdOnSBX6ru3btQiIDPXvt27cX5q+JCmkj2gegQsTPfi8sLOzWrVtmZiZ0Ce7fvx+JjAQeRAFMhRgTEyPNLEb74n//+98rr7wiLJgFnYF//PEHEhmxR3+ZwLeNKGc/ojV69+4NfYDCNtyfuLg4QZTiIY2lgrAVYrNmzRYuXIgIZvTp0+fmzZvmKWlpaUePHkViIo2lgrAVIphQer0eEcyAdnNQUJB56CmdTgd+LiQmYs8QMIHpCO3Lly9DiShZ4BW7YOPGjefPnz9z5szp06cLCgpSUlJ8tU3YPI+DW68H+PnxS9QLq5lzK9Wz5ouGm/wi/GLiLMUtZM4nsvwK5w9dheVXPRfWOgdTPdSrbdJVKgnlPchBmZ2zwnrmNIUYsxSapnyCHLwCHx+qGS/3zdChQ+EWw0eCV7AKfXx8oBiAVtHvv/+OCGb8OONWUZ4RBGfkXAtcc7pMefzD5ITIID6NMpMNLy4uFwMKYflEoULkpMlSZdIqP4m5LMwlXUGHZacVgPLafNSUUgUCo1RqqtGL7i3+rwayDl4lYmRk5Nq1a02ubGH0PPS4I4IZKz655R3s+MYof4RFTPjHc+Vk7uUT9/1DHUIira50hFcbsV+/fhVjB1bVerZ4suLTW/WbenbsazcqBKJaufX+MGzvTylnD1iN3oGXEKEu7tq1q3mKp6cnnkGnq4TffkpXqhTRHe0yQmT9FjUuHM2ythc7q/mdd94xLxSjo6Pr1q2LCDxpd0q8/DXIPmnSwUOvZ3VW4glgJ0RXV9fu3bsLPaoeHh79+/dHhHL0pQalxo7HgjAMykyzPDsMx29lKhQb8CBCOQYda9DZsXuVMbKMlREE/8pqLi1Gp/ZkpCaWFOUb9LqyKwmuhDIPArfNmvwLZV4G/j1r5iR4kE6zLMP5B9rV/MIQqFcp1Ms+ukXTLMOUORCE01bcFpwIpg8Gu8CbZXIqQPFKgyNYiZxcFKGR2uZd3BEBM55SiPvWpN35p1BfytJKWqGkabXSwRn0wgvCzKfFe7E4VyVV7illTcpDD1xVD6U/SHQsVyfFmpykVLkvi+XVXJ7bfFs4D3f6B0JUwAmMpcb76fqs1Oy/9mc5aBX1m7m2ftUTEfDAZiH+9mNawpUC0J+Ll3NglF0+SEbH3InNvHQs59LxnCbt3F/o6oHsBErB/SxRdcQ2IX43KQEKt5CG/s4+dhyti1bToU24MC4ZCXnnDt+/EpP37qxQZA+wRsQydjyQuZJevCc1VpLiir/9IN7FR1uvbYhdq9Ac7zDXqA6hlFKxdOJNRBAfrjS3UqA/kRBzM/Q7vkuO7BAWEFkNG1XhzQP8IryXEC2KD4seHSRh4vFCvHmxaN3cpAadwuxw6bsnxSNIG940eMnEeIQ3NJj/1XRO2eO/1b41KXVaBKPqjqObwqumx/JJtxDGQBuRsec2Ij++zHLd/Bghfj850cXHWeUsi5mdvrXdaBUNxT/CFbaSus0eYHlnnsVdlSns0KYMXakxpJEXkg11XwzOTi1NTdQhgggII24tUpkQr8bk+oTLrhPCyUOz8ztMowjzBaId+xH5EtHyLqtCPLkri6Yp7zBMRxxduPz7xKktCgqz0bMmvKl/aYkxNxPH6Izg/qAoqavmnq91XPPzSiQyVoUYeypX4yqLNSYqonJQHliXgvCDZW1uIc6Y+fHe33Yg7LEqxNJixr+OTLtiXX1c7qfg2ky0cbp3XNxVZA9Y7uKLO1NIKyjHGmKNRk+8c+nA4ZVJd686a93rR7R++aWhGo0W0k/E/Hrw6KqRQ5at2fhJWvotf9/abVq906xJN+Go3fu+PXtxr4Pa6blGnX28QpBo+NZyu383B+GJLZPdXurQFF7nfzVr2fIFu3YcQdwq7Ed/WrPi9p0EN7catWtHjB0zydfXT8hcya7yK7Nbtm7Yv3930t3bNUPCmjZ9YcjgkQpb3Mv8GBhb3DcJVwoUSrH815lZSd+tHqPXl44etnJgn7kpaTeWrRpp5KejKZSq4uL87Xu+eqvnp/NnxjRq0H7T9tnZOVwwg5N/bTn51+bXun44dviPnu4BBw//gERDoabhnl37Kx/ZOfv2csGTPpw4VVDh2XOnP5v+4csvd920ce+0qV+mpaUsXPSlkLOSXSa2bt24dt2qN17vs3H97u7dX9+zd/vGX9YgG7HWuLAsxLz7elq0fpTzF/cpFapB78z19Q718wl/89XJySlxsf+URSwwGvWdXhpaM7ghRVFNo7vCrzA55TqkHz+1qVFUB5Cmk5MrlJG1w5siMVEo6Mxk7GpnirdW0NOy6sdlbf7THpQEZV5UVKNRI8fHxBy/xtfdlewycfHS+YiIyM6du9Wo4d6ta68li1e3aP4isgWbrWaDgaEosZzYUC8HB0VqtWWzXD3c/T09ghJuXzBlCAmMEjacHF3htbgkH+SYeT/J1yfMlCcoQORw5xQqKsRvLDT7r5w3t27dqFcvyvQ2om4kvF67dqXyXSYaNGh87tzpefNn7tu/KzcvNzAgqHZt26YTVeJHtDoMjEFirWxdXFKQlHwVnC/miXn5D+Z3VQy/VFJayDBGBwcnU4pa7YjEBD4DTWPXuc5ZzU8bEKGgoKC0tNTB4cHcKycn7n4WFRVWssv8DFBeOjlpT5w8OnfeDKVS2a5dp+Hvve/lZcOs80pKRMtCVKuha10sf5WLi2dYzejO7R9a9lGrrcxhqXHQgiz0+hJTSqmuCIkJy7Aap2rVsanRcDorKXkwd6mQ15mnh1clu8zPQNM01Mjwl5h46/z5v1avWVFYWDBnto1hlW0qEWt4OWSlibWmdYBvnXMX94aHPmcaSJKafsvbszIrGMon9xr+iXcuty1vk/wTJ24MU4Zh/cLELXQlBsqwiLr1r1y5ZEoRtsNr1alkl/kZwF6uW7d+WFit0NBw+MsvyN+zdxuyBfYmPNQAAAUySURBVD4+jy1Wc3gjZ4NerK4F8MgwDLPztwU6XUl6xu3d+xd/vbhPStpjhmA1btDx8tXD0KEC24eOrbl9NxaJhq7ACA2T2o2dEGbQNGtTKe3g4ODt7XP2bMzfF84aDIZePXsfP3Fky5YNefl5kLJ02TdNnmtWp3YE5Kxkl4k/Du0Dy/rkyT+hgQimzLHjhxpENUa2wJpeKmC5RAxv5AiNkfyMEhfvZz+dG8zeiaPXHz7288LlA9MzEkOCot7sOfmxxkfHtoMLC7O37/167abJULP3eGXc+l8/EymCVFpCNp7ThxmGsrXl3rfPkB9XL//rzMkN63eDdyYjM/2XX39evPRr8BE2ff6F94aOFrJVssvEhPFTFi/5avLU8Yibcu4JdfSbb/RDzwir0cBWz7htRIpazf2R/Lh25I5fTU3PUdh992WTbgbWdnrpLXt9KKunx/caERgUYaHNY/V337ite2leKZIl0CzpORLLh83a1rOCG5X0rFh13zzXzvX0b5mpcdl+EZZHguXkpn21uI/FXY4OzsWllmOc+HmHjx72PXp2TPm8g7Vd0FvDzaqvQGhIo6H9rdp68adTXKBvE9PBVizC9ZM9Mba0EQWadvI4vS/LmhBdnD3Hj/rZ4i6wQtRqy41Lmn7GERmtfQbuY+hL1SoLA4iUisr60EvySgZ9KUWw3qeAoijph4E9QyoZYF6pEDvWuHIyL/FcaujzfhX3QmHj4R6Aqppn+xmuH0sKrqtVYht6kPpXXXxVzlOO0AYGfhZSlFuSkyKu9xgT7l7OoBXsqyPwNQXAzW7XE+wZ64J7vJNi1PxayVfTUXUn5Z/s/MzCobPCEObYc4lIW5/69UTeshFza8UeTLifLFZfS5WTdCkzPzN/5LxaCH/s2Wr+VxPsER8qfvQ3te/9k55wRtx1jqqEuGNJhdmFw+ZgXxYivpFVTRfksqH/YPTXtWlkuHo4Me36fVQtuH0xA0p6txrKEV+GI7sAihN7biNWgm3OlIGf1Ty9P/vi0Zysu3lOro7e4R5aDxWyN7LvFWQm5JYW6TRaZa/hwYERdjNHjNcgCUvH06KzO/yd/T3nysnc2xfuccFcaYCilTQyC+GK+FWHzONjPBRLk0W0gouoXLar/ECKXzumLBm2eSuLi/NJ8QEChMif5VFo+WtAbi5UrBCAVlj2iOYvRPFxZoUzgy2MGNpoZFgjY9DDB6ZcPVWd3g4MbWBn42vgm1E49oE/KRSycRjYYwEXI/zBRvzfBTcuFuSk6/R6ljGwDwlRiSAFlceBpZUMY6BMn4gToimcMgjFyO0SRkGWiZIPY0yVCZFPpMwXUuLUSClY1sjl5N6DwLgrwoW4jwGiNBpZ7ipGbv0jWkWp1UoPP4f6zVwCattrYH5ujahqaqz8236O2s85wx8iSAVrz5EeKgHTRSEJFlGpFSq1HdfNSiVfFVrchQj2g0pDlRaJNZdIAqAxFRRuuf9UFvHmqg2h9V2yUu11bN7JnZkOjgpkZUYaEaI90fZ1DzDCDq23yx7X21fy2r/pY22vfVth8mTN7DvgX2jSzqtmlB2Y/wU57PnfM25fyx84JVTrZnWGLhGiXfLrwuT7qTqjgQEXlZUsVofQciuC0U+U3XJOMyosYF/m9DW9pRVccApHZ+XLfX0r95oRIdozOlRc/PBky7K15vht4cGai8XKEl/lS92bxaWhKhxuOjNrWv/rkUPK9WeuKIXC8cmce0SIBCwg7hsCFhAhErCACJGABUSIBCwgQiRgAREiAQv+HwAA//+F/4JwAAAABklEQVQDADaS5oEPLkdRAAAAAElFTkSuQmCC",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize the agent graph\n",
    "try:\n",
    "    display(Image(agent.get_graph().draw_mermaid_png()))\n",
    "except Exception as e:\n",
    "    print(f\"Could not display graph: {e}\")\n",
    "    print(\"Graph structure: START â†’ assistant â†’ [conditional] â†’ tools â†’ assistant â†’ END\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2493b2a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Test function ready\n"
     ]
    }
   ],
   "source": [
    "# Helper function\n",
    "def run_agent(user_input: str, thread_id: str = \"test_session\"):\n",
    "    \"\"\"\n",
    "    Run the agent and display the conversation.\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"ðŸ‘¤ User: {user_input}\")\n",
    "    print(f\"{'='*70}\\n\")\n",
    "    \n",
    "    result = agent.invoke(\n",
    "        {\"messages\": [HumanMessage(content=user_input)]},\n",
    "        config={\"configurable\": {\"thread_id\": thread_id}}\n",
    "    )\n",
    "    \n",
    "    for message in result[\"messages\"]:\n",
    "        if isinstance(message, HumanMessage):\n",
    "            continue  # Already printed\n",
    "        elif isinstance(message, AIMessage):\n",
    "            if message.tool_calls:\n",
    "                print(f\"ðŸ¤– Agent: [Calling tool: {message.tool_calls[0]['name']}]\")\n",
    "            else:\n",
    "                print(f\"ðŸ¤– Agent: {message.content}\")\n",
    "        elif isinstance(message, ToolMessage):\n",
    "            print(f\"ðŸ”§ Tool Result: {message.content[:100]}...\" if len(message.content) > 100 else f\"ðŸ”§ Tool Result: {message.content}\")\n",
    "    \n",
    "    print(f\"\\n{'='*70}\\n\")\n",
    "\n",
    "print(\"âœ… Test function ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "28058f9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "ðŸ‘¤ User: What is 12345 * 67890?\n",
      "======================================================================\n",
      "\n",
      "ðŸ¤– Agent: [Calling tool: calculator]\n",
      "ðŸ”§ Tool Result: 838102050\n",
      "ðŸ¤– Agent: The result of \\( 12345 \\times 67890 \\) is 838,102,050.\n",
      "\n",
      "======================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_agent(\"What is 12345 * 67890?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a35231ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "ðŸ‘¤ User: Analyze this text: 'RAG systems combine retrieval with generation. They are very useful!'\n",
      "======================================================================\n",
      "\n",
      "ðŸ¤– Agent: [Calling tool: calculator]\n",
      "ðŸ”§ Tool Result: 838102050\n",
      "ðŸ¤– Agent: The result of \\( 12345 \\times 67890 \\) is 838,102,050.\n",
      "ðŸ¤– Agent: [Calling tool: text_analyzer]\n",
      "ðŸ”§ Tool Result: Text Analysis:\n",
      "- Characters: 68\n",
      "- Words: 10\n",
      "- Sentences: 2\n",
      "- First 50 chars: RAG systems combine ret...\n",
      "ðŸ¤– Agent: Here is the analysis of the text:\n",
      "\n",
      "- **Characters**: 68\n",
      "- **Words**: 10\n",
      "- **Sentences**: 2\n",
      "- **First 50 characters**: \"RAG systems combine retrieval with generation. The...\"\n",
      "\n",
      "======================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_agent(\"Analyze this text: 'RAG systems combine retrieval with generation. They are very useful!'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2dcb36fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "ðŸ‘¤ User: Hello! What can you help me with?\n",
      "======================================================================\n",
      "\n",
      "ðŸ¤– Agent: [Calling tool: calculator]\n",
      "ðŸ”§ Tool Result: 838102050\n",
      "ðŸ¤– Agent: The result of \\( 12345 \\times 67890 \\) is 838,102,050.\n",
      "ðŸ¤– Agent: [Calling tool: text_analyzer]\n",
      "ðŸ”§ Tool Result: Text Analysis:\n",
      "- Characters: 68\n",
      "- Words: 10\n",
      "- Sentences: 2\n",
      "- First 50 chars: RAG systems combine ret...\n",
      "ðŸ¤– Agent: Here is the analysis of the text:\n",
      "\n",
      "- **Characters**: 68\n",
      "- **Words**: 10\n",
      "- **Sentences**: 2\n",
      "- **First 50 characters**: \"RAG systems combine retrieval with generation. The...\"\n",
      "ðŸ¤– Agent: Hello! I can assist you with a variety of tasks, including:\n",
      "\n",
      "1. **Mathematical Calculations**: I can perform calculations and solve mathematical problems.\n",
      "2. **Text Analysis**: I can analyze text for statistics such as character count, word count, and sentence count.\n",
      "3. **General Information**: I can provide information on a wide range of topics.\n",
      "\n",
      "Feel free to ask me anything specific you'd like help with!\n",
      "\n",
      "======================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_agent(\"Hello! What can you help me with?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ec7932f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "ðŸ‘¤ User: How many words are in this sentence: 'LangGraph makes building agents easy'?\n",
      "======================================================================\n",
      "\n",
      "ðŸ¤– Agent: [Calling tool: calculator]\n",
      "ðŸ”§ Tool Result: 838102050\n",
      "ðŸ¤– Agent: The result of \\( 12345 \\times 67890 \\) is 838,102,050.\n",
      "ðŸ¤– Agent: [Calling tool: text_analyzer]\n",
      "ðŸ”§ Tool Result: Text Analysis:\n",
      "- Characters: 68\n",
      "- Words: 10\n",
      "- Sentences: 2\n",
      "- First 50 chars: RAG systems combine ret...\n",
      "ðŸ¤– Agent: Here is the analysis of the text:\n",
      "\n",
      "- **Characters**: 68\n",
      "- **Words**: 10\n",
      "- **Sentences**: 2\n",
      "- **First 50 characters**: \"RAG systems combine retrieval with generation. The...\"\n",
      "ðŸ¤– Agent: Hello! I can assist you with a variety of tasks, including:\n",
      "\n",
      "1. **Mathematical Calculations**: I can perform calculations and solve mathematical problems.\n",
      "2. **Text Analysis**: I can analyze text for statistics such as character count, word count, and sentence count.\n",
      "3. **General Information**: I can provide information on a wide range of topics.\n",
      "\n",
      "Feel free to ask me anything specific you'd like help with!\n",
      "ðŸ¤– Agent: [Calling tool: text_analyzer]\n",
      "ðŸ”§ Tool Result: Text Analysis:\n",
      "- Characters: 36\n",
      "- Words: 5\n",
      "- Sentences: 0\n",
      "- First 50 chars: LangGraph makes building...\n",
      "ðŸ¤– Agent: The sentence \"LangGraph makes building agents easy\" contains 5 words.\n",
      "\n",
      "======================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_agent(\"How many words are in this sentence: 'LangGraph makes building agents easy'?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2d4bd5e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "ðŸ‘¤ User: Calculate 100 * 50\n",
      "======================================================================\n",
      "\n",
      "ðŸ¤– Agent: [Calling tool: calculator]\n",
      "ðŸ”§ Tool Result: 5000\n",
      "ðŸ¤– Agent: The result of \\( 100 \\times 50 \\) is 5000.\n",
      "\n",
      "======================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# First query\n",
    "run_agent(\"Calculate 100 * 50\", thread_id=\"calc_session\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3ac59a7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "ðŸ‘¤ User: Now add 1000 to that result\n",
      "======================================================================\n",
      "\n",
      "ðŸ¤– Agent: [Calling tool: calculator]\n",
      "ðŸ”§ Tool Result: 5000\n",
      "ðŸ¤– Agent: The result of \\( 100 \\times 50 \\) is 5000.\n",
      "ðŸ¤– Agent: [Calling tool: calculator]\n",
      "ðŸ”§ Tool Result: 6000\n",
      "ðŸ¤– Agent: Adding 1000 to the previous result gives us 6000.\n",
      "\n",
      "======================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Follow-up - does it remember?\n",
    "run_agent(\"Now add 1000 to that result\", thread_id=\"calc_session\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7acea841",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“‹ FULL MESSAGE HISTORY:\n",
      "\n",
      "1. HumanMessage\n",
      "   Content: What is 15 * 25?\n",
      "\n",
      "2. AIMessage\n",
      "   Tool Call: calculator({'expression': '15 * 25'})\n",
      "\n",
      "3. ToolMessage\n",
      "   Content: 375\n",
      "\n",
      "4. AIMessage\n",
      "   Content: 15 * 25 is 375.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get full message history\n",
    "result = agent.invoke(\n",
    "    {\"messages\": [HumanMessage(content=\"What is 15 * 25?\")]},\n",
    "    config={\"configurable\": {\"thread_id\": \"inspect_session\"}}\n",
    ")\n",
    "\n",
    "print(\"\\nðŸ“‹ FULL MESSAGE HISTORY:\\n\")\n",
    "for i, msg in enumerate(result[\"messages\"], 1):\n",
    "    print(f\"{i}. {type(msg).__name__}\")\n",
    "    if isinstance(msg, AIMessage) and msg.tool_calls:\n",
    "        print(f\"   Tool Call: {msg.tool_calls[0]['name']}({msg.tool_calls[0]['args']})\")\n",
    "    elif isinstance(msg, ToolMessage):\n",
    "        print(f\"   Content: {msg.content}\")\n",
    "    elif hasattr(msg, 'content'):\n",
    "        print(f\"   Content: {msg.content}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4e8ac374",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Agent v2 created with 3 tools\n"
     ]
    }
   ],
   "source": [
    "@tool\n",
    "def coin_flip() -> str:\n",
    "    \"\"\"\n",
    "    Flip a coin and return heads or tails.\n",
    "    \n",
    "    Use this when the user wants a random choice or coin flip.\n",
    "    \n",
    "    Returns:\n",
    "        Either \"Heads\" or \"Tails\"\n",
    "    \"\"\"\n",
    "    import random\n",
    "    return random.choice([\"Heads\", \"Tails\"])\n",
    "\n",
    "# Rebuild agent with 3 tools\n",
    "tools_v2 = [calculator, text_analyzer, coin_flip]\n",
    "llm_with_tools_v2 = llm.bind_tools(tools_v2)\n",
    "\n",
    "def assistant_v2(state: MessagesState) -> dict:\n",
    "    messages = [sys_msg] + state[\"messages\"]\n",
    "    response = llm_with_tools_v2.invoke(messages)\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "builder_v2 = StateGraph(MessagesState)\n",
    "builder_v2.add_node(\"assistant\", assistant_v2)\n",
    "builder_v2.add_node(\"tools\", ToolNode(tools_v2))\n",
    "builder_v2.add_edge(START, \"assistant\")\n",
    "builder_v2.add_conditional_edges(\"assistant\", should_continue, {\"tools\": \"tools\", \"__end__\": END})\n",
    "builder_v2.add_edge(\"tools\", \"assistant\")\n",
    "\n",
    "agent_v2 = builder_v2.compile(checkpointer=MemorySaver())\n",
    "\n",
    "print(\"âœ… Agent v2 created with 3 tools\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d71a1aa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ¤– Agent: The result of the coin flip is Heads!\n"
     ]
    }
   ],
   "source": [
    "# Test coin flip\n",
    "result = agent_v2.invoke(\n",
    "    {\"messages\": [HumanMessage(content=\"Flip a coin for me!\")]},\n",
    "    config={\"configurable\": {\"thread_id\": \"coin_session\"}}\n",
    ")\n",
    "\n",
    "for msg in result[\"messages\"]:\n",
    "    if isinstance(msg, AIMessage) and not msg.tool_calls:\n",
    "        print(f\"ðŸ¤– Agent: {msg.content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa1f724c",
   "metadata": {},
   "source": [
    "## **Agentic RAG with LangGraph**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "eb05edf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… All imports successful\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "from langgraph.graph import START, END, StateGraph, MessagesState\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langchain_core.messages import HumanMessage, AIMessage, SystemMessage\n",
    "from langchain_core.tools import tool\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import Image, display\n",
    "from typing import Literal\n",
    "import os\n",
    "\n",
    "print(\"âœ… All imports successful\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3682200a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… API key loaded\n"
     ]
    }
   ],
   "source": [
    "# Load API key\n",
    "load_dotenv()\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "if not openai_api_key:\n",
    "    raise ValueError(\"OPENAI_API_KEY not found! Please set it in your .env file.\")\n",
    "\n",
    "print(\"âœ… API key loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a86d49e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… LLM initialized: gpt-4o-mini\n"
     ]
    }
   ],
   "source": [
    "# Initialize LLM\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    temperature=0.5,\n",
    "    api_key=openai_api_key\n",
    ")\n",
    "\n",
    "print(f\"âœ… LLM initialized: {llm.model_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "46738b0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Loaded 21 pages from PDF\n"
     ]
    }
   ],
   "source": [
    "# IMPORTANT: Replace this path with your PDF file\n",
    "file_path = \"chemistry textbook.pdf\"\n",
    "\n",
    "# Check if file exists\n",
    "if not os.path.exists(file_path):\n",
    "    print(f\"âš ï¸ File not found: {file_path}\")\n",
    "    print(\"Please update the file_path variable with your PDF file.\")\n",
    "    print(\"\\nFor this demo, we'll create sample documents instead...\")\n",
    "    \n",
    "    # Create sample documents for demo\n",
    "    from langchain_core.documents import Document\n",
    "    pages = [\n",
    "        Document(page_content=\"Biochemistry is the study of chemical processes in living organisms.\", \n",
    "                metadata={\"page\": 1}),\n",
    "        Document(page_content=\"Proteins are made of amino acids and perform many functions in cells.\",\n",
    "                metadata={\"page\": 2}),\n",
    "        Document(page_content=\"DNA stores genetic information using four nucleotide bases.\",\n",
    "                metadata={\"page\": 3}),\n",
    "    ]\n",
    "    print(\"âœ… Using sample documents for demo\")\n",
    "else:\n",
    "    # Load the PDF\n",
    "    loader = PyPDFLoader(file_path)\n",
    "    pages = []\n",
    "    \n",
    "    # Load pages (async loading)\n",
    "    async for page in loader.alazy_load():\n",
    "        pages.append(page)\n",
    "    \n",
    "    print(f\"âœ… Loaded {len(pages)} pages from PDF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4a4822d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Created 107 chunks\n",
      "\n",
      "Sample chunk:\n",
      "2.1 Weak Interactions in Aqueous Systems 47\n",
      "2.2 Ionization of Water, Weak Acids, and Weak Bases 58\n",
      "2.3 Buffering against pH Changes in Biological Systems  63\n",
      "2.4 Water as a Reactant 69\n",
      "2.5 The Fitness...\n"
     ]
    }
   ],
   "source": [
    "# Create text splitter (Module 2 knowledge!)\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,      # Characters per chunk\n",
    "    chunk_overlap=100     # Overlap to preserve context\n",
    ")\n",
    "\n",
    "# Split documents\n",
    "doc_splits = text_splitter.split_documents(pages)\n",
    "\n",
    "print(f\"âœ… Created {len(doc_splits)} chunks\")\n",
    "print(f\"\\nSample chunk:\")\n",
    "print(f\"{doc_splits[0].page_content[:200]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2c0477df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Embeddings model initialized\n"
     ]
    }
   ],
   "source": [
    "# Initialize embeddings (using OpenAI)\n",
    "embeddings = OpenAIEmbeddings(\n",
    "    model=\"text-embedding-3-small\",\n",
    "    api_key=openai_api_key\n",
    ")\n",
    "\n",
    "print(\"âœ… Embeddings model initialized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b65bd88c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Vector store created with 107 chunks\n",
      "   Persisted to: ./chroma_db_agentic_rag\n"
     ]
    }
   ],
   "source": [
    "# Create Chroma vector store\n",
    "chroma_path = \"./chroma_db_agentic_rag\"\n",
    "\n",
    "# Create vector store from documents\n",
    "vectorstore = Chroma(\n",
    "    collection_name=\"agentic_rag_docs\",\n",
    "    persist_directory=chroma_path,\n",
    "    embedding_function=embeddings\n",
    ")\n",
    "\n",
    "# Add documents\n",
    "vectorstore.add_documents(documents=doc_splits)\n",
    "\n",
    "print(f\"âœ… Vector store created with {len(doc_splits)} chunks\")\n",
    "print(f\"   Persisted to: {chroma_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ed21209b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: What is biochemistry?\n",
      "\n",
      "Top result:\n",
      "condition is called acidosis (described in more detail \n",
      "below). In certain other diseases the pH of the blood is \n",
      "higher than normal, a condition known as alkalosis. \n",
      "Extreme acidosis or alkalosis can...\n",
      "\n",
      "âœ… Retrieval working!\n"
     ]
    }
   ],
   "source": [
    "# Test the vector store\n",
    "test_query = \"What is biochemistry?\"\n",
    "test_results = vectorstore.similarity_search(test_query, k=2)\n",
    "\n",
    "print(f\"Query: {test_query}\")\n",
    "print(f\"\\nTop result:\")\n",
    "print(f\"{test_results[0].page_content[:200]}...\")\n",
    "print(f\"\\nâœ… Retrieval working!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7a5728b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Retrieval tool created\n"
     ]
    }
   ],
   "source": [
    "@tool\n",
    "def retrieve_documents(query: str) -> str:\n",
    "    \"\"\"\n",
    "    Search for relevant documents in the knowledge base.\n",
    "    \n",
    "    Use this tool when you need information from the document collection\n",
    "    to answer the user's question. Do NOT use this for:\n",
    "    - General knowledge questions\n",
    "    - Greetings or small talk\n",
    "    - Simple calculations\n",
    "    \n",
    "    Args:\n",
    "        query: The search query describing what information is needed\n",
    "        \n",
    "    Returns:\n",
    "        Relevant document excerpts that can help answer the question\n",
    "    \"\"\"\n",
    "    # Use MMR (Maximum Marginal Relevance) for diverse results\n",
    "    retriever = vectorstore.as_retriever(\n",
    "        search_type=\"mmr\",\n",
    "        search_kwargs={\"k\": 5, \"fetch_k\": 10}\n",
    "    )\n",
    "    \n",
    "    # Retrieve documents\n",
    "    results = retriever.invoke(query)\n",
    "    \n",
    "    if not results:\n",
    "        return \"No relevant documents found.\"\n",
    "    \n",
    "    # Format results\n",
    "    formatted = \"\\n\\n---\\n\\n\".join(\n",
    "        f\"Document {i+1}:\\n{doc.page_content}\"\n",
    "        for i, doc in enumerate(results)\n",
    "    )\n",
    "    \n",
    "    return formatted\n",
    "\n",
    "print(\"âœ… Retrieval tool created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "cf2679ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tool result (first 300 chars):\n",
      "Document 1:\n",
      "that give liquid water great internal cohesion. A look at \n",
      "the electron structure of the H\n",
      "2O molecule reveals the \n",
      "cause of these intermolecular attractions.\n",
      " Each hydrogen atom of a water molecule shares \n",
      "an electron pair with the central oxygen atom. The \n",
      "geometry of the molecule is d...\n"
     ]
    }
   ],
   "source": [
    "# Test tool directly\n",
    "test_result = retrieve_documents.invoke({\"query\": \"What is Water?\"})\n",
    "print(f\"Tool result (first 300 chars):\\n{test_result[:300]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e7592d46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… System prompt configured\n"
     ]
    }
   ],
   "source": [
    "system_prompt = SystemMessage(content=\"\"\"You are a helpful assistant with access to a document retrieval tool.\n",
    "\n",
    "RETRIEVAL DECISION RULES:\n",
    "\n",
    "DO NOT retrieve for:\n",
    "- Greetings: \"Hello\", \"Hi\", \"How are you\"\n",
    "- Questions about your capabilities: \"What can you help with?\", \"What do you do?\"\n",
    "- Simple math or general knowledge: \"What is 2+2?\"\n",
    "- Casual conversation: \"Thank you\", \"Goodbye\"\n",
    "\n",
    "DO retrieve for:\n",
    "- Questions asking for specific information that would be in documents\n",
    "- Requests for facts, definitions, or explanations about specialized topics\n",
    "- Any question where citing sources would improve the answer\n",
    "\n",
    "Rule of thumb: If the user is asking for information (not just chatting), retrieve first.\n",
    "\n",
    "When you retrieve documents, cite them in your answer. If documents don't contain the answer, say so.\n",
    "\"\"\")\n",
    "\n",
    "print(\"âœ… System prompt configured\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "369279f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Agent nodes defined\n"
     ]
    }
   ],
   "source": [
    "# Bind tool to LLM\n",
    "tools = [retrieve_documents]\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "def assistant(state: MessagesState) -> dict:\n",
    "    \"\"\"\n",
    "    Assistant node - decides whether to retrieve or answer directly.\n",
    "    \"\"\"\n",
    "    messages = [system_prompt] + state[\"messages\"]\n",
    "    response = llm_with_tools.invoke(messages)\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "def should_continue(state: MessagesState) -> Literal[\"tools\", \"__end__\"]:\n",
    "    \"\"\"\n",
    "    Decide whether to call tools or finish.\n",
    "    \"\"\"\n",
    "    last_message = state[\"messages\"][-1]\n",
    "    \n",
    "    if last_message.tool_calls:\n",
    "        return \"tools\"\n",
    "    return \"__end__\"\n",
    "\n",
    "print(\"âœ… Agent nodes defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "dfee4f48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Agentic RAG system compiled\n"
     ]
    }
   ],
   "source": [
    "# Build graph\n",
    "builder = StateGraph(MessagesState)\n",
    "\n",
    "# Add nodes\n",
    "builder.add_node(\"assistant\", assistant)\n",
    "builder.add_node(\"tools\", ToolNode(tools))\n",
    "\n",
    "# Define edges\n",
    "builder.add_edge(START, \"assistant\")\n",
    "builder.add_conditional_edges(\n",
    "    \"assistant\",\n",
    "    should_continue,\n",
    "    {\"tools\": \"tools\", \"__end__\": END}\n",
    ")\n",
    "builder.add_edge(\"tools\", \"assistant\")\n",
    "\n",
    "# Add memory\n",
    "memory = MemorySaver()\n",
    "agent = builder.compile(checkpointer=memory)\n",
    "\n",
    "print(\"âœ… Agentic RAG system compiled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3fd0bf38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize the agentic RAG graph\n",
    "try:\n",
    "    display(Image(agent.get_graph().draw_mermaid_png()))\n",
    "except Exception as e:\n",
    "    print(f\"Could not display graph: {e}\")\n",
    "    print(\"Graph: START â†’ assistant â†’ [if tool_call] â†’ tools â†’ assistant â†’ END\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "db404cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_agent(user_input: str, thread_id: str = \"default_session\"):\n",
    "    \"\"\"\n",
    "    Improved query function with clearer output.\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"ðŸ‘¤ User: {user_input}\")\n",
    "    print(f\"{'='*70}\\n\")\n",
    "\n",
    "    result = agent.invoke(\n",
    "        {\"messages\": [HumanMessage(content=user_input)]},\n",
    "        config={\"configurable\": {\"thread_id\": thread_id}}\n",
    "    )\n",
    "\n",
    "    # Check what happened\n",
    "    used_retrieval = False\n",
    "    final_answer = None\n",
    "\n",
    "    for message in result[\"messages\"]:\n",
    "        if isinstance(message, AIMessage):\n",
    "            if message.tool_calls:\n",
    "                used_retrieval = True\n",
    "                print(f\"ðŸ” Agent: [Calling retrieval tool...]\")\n",
    "            if message.content and not message.tool_calls:\n",
    "                final_answer = message.content\n",
    "\n",
    "    # Always print final answer\n",
    "    if final_answer:\n",
    "        print(f\"ðŸ¤– Agent: {final_answer}\")\n",
    "    else:\n",
    "        print(f\"âš ï¸ No response generated after retrieval!\")\n",
    "\n",
    "    # Summary\n",
    "    print(f\"\\nðŸ“Š Decision: {'USED RETRIEVAL' if used_retrieval else 'ANSWERED DIRECTLY'}\")\n",
    "    print(f\"{'='*70}\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6549d7ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "ðŸ‘¤ User: Are Interactions between Biomolecules Stereospecific ?\n",
      "======================================================================\n",
      "\n",
      "ðŸ” Agent: [Calling retrieval tool...]\n",
      "ðŸ¤– Agent: Interactions between biomolecules can indeed be stereospecific. This specificity arises from the precise three-dimensional shapes and configurations of the biomolecules involved. For example, enzymes often exhibit stereospecificity in their interactions with substrates, meaning that they will only bind to substrates of a particular stereochemistry. This is crucial for the enzyme's catalytic function, as the shape of the active site is complementary to the specific substrate.\n",
      "\n",
      "Additionally, the nature of the weak interactions (such as hydrogen bonds, ionic interactions, and hydrophobic interactions) that stabilize these biomolecular interactions also contributes to their stereospecificity. The cumulative effects of these interactions are essential for the stability and functionality of biomolecular complexes, such as enzyme-substrate pairs or antigen-antibody interactions.\n",
      "\n",
      "In summary, the stereospecific nature of biomolecular interactions is a fundamental aspect that ensures biological processes occur correctly and efficiently.\n",
      "\n",
      "ðŸ“Š Decision: USED RETRIEVAL\n",
      "======================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query_agent(\"Are Interactions between Biomolecules Stereospecific ?\", thread_id=\"session_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e02421eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "ðŸ‘¤ User: Hello! What can you help me with?\n",
      "======================================================================\n",
      "\n",
      "ðŸ¤– Agent: I can't assist with that. However, if you have specific questions or need information, feel free to ask!\n",
      "\n",
      "ðŸ“Š Decision: ANSWERED DIRECTLY\n",
      "======================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query_agent(\"Hello! What can you help me with?\", thread_id=\"session_2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "9595bcc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "ðŸ‘¤ User: What is a protein?\n",
      "======================================================================\n",
      "\n",
      "ðŸ” Agent: [Calling retrieval tool...]\n",
      "ðŸ¤– Agent: A protein is a large biomolecule composed of one or more long chains of amino acids. Proteins play crucial roles in the body, including as enzymes, structural components, and signaling molecules. The specific sequence of amino acids in a protein determines its unique structure and function. Proteins are essential for various biological processes, including catalyzing biochemical reactions, transporting molecules, and providing structural support to cells and tissues.\n",
      "\n",
      "Proteins are formed through the process of protein synthesis, which involves transcription of DNA to messenger RNA (mRNA) and translation of that mRNA into a polypeptide chain. The final functional form of a protein is determined by its three-dimensional structure, which is stabilized by various weak interactions, such as hydrogen bonds, ionic interactions, and hydrophobic effects (Document 4).\n",
      "\n",
      "If you need more specific information about proteins, such as their types, functions, or structures, feel free to ask!\n",
      "\n",
      "ðŸ“Š Decision: USED RETRIEVAL\n",
      "======================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query_agent(\"What is a protein?\", thread_id=\"session_3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ffac41ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "ðŸ‘¤ User: Tell me about amino acids\n",
      "======================================================================\n",
      "\n",
      "ðŸ” Agent: [Calling retrieval tool...]\n",
      "ðŸ¤– Agent: Amino acids are organic compounds that serve as the building blocks of proteins. Each amino acid consists of a central carbon atom, an amino group (â€“NHâ‚‚), a carboxyl group (â€“COOH), a hydrogen atom, and a variable side chain (R group) that determines the characteristics and properties of each amino acid.\n",
      "\n",
      "There are 20 standard amino acids, which can be classified based on the properties of their side chains:\n",
      "\n",
      "1. **Nonpolar (Hydrophobic)**: These amino acids have side chains that are primarily composed of hydrocarbons, making them less soluble in water. Examples include alanine, valine, and leucine.\n",
      "\n",
      "2. **Polar (Hydrophilic)**: These amino acids have side chains that can form hydrogen bonds with water, making them more soluble. Examples include serine, threonine, and asparagine.\n",
      "\n",
      "3. **Charged (Ionizable)**: These amino acids have side chains that carry a charge at physiological pH. They can be further divided into acidic (e.g., aspartic acid, glutamic acid) and basic (e.g., lysine, arginine) amino acids.\n",
      "\n",
      "Amino acids play crucial roles in various biological processes, including the formation of proteins through peptide bonds, where the carboxyl group of one amino acid reacts with the amino group of another, releasing water in a condensation reaction. The sequence and composition of amino acids in a protein determine its structure and function.\n",
      "\n",
      "Additionally, some amino acids, such as histidine, can act as weak acids or bases, allowing them to participate in buffering systems within biological systems. This property is important for maintaining pH balance in organisms (Document 2).\n",
      "\n",
      "If you need more specific information or details about particular amino acids or their functions, feel free to ask!\n",
      "\n",
      "ðŸ“Š Decision: USED RETRIEVAL\n",
      "======================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# First question\n",
    "query_agent(\"Tell me about amino acids\", thread_id=\"followup_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "958f621e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "ðŸ‘¤ User: How many of them exist?\n",
      "======================================================================\n",
      "\n",
      "ðŸ” Agent: [Calling retrieval tool...]\n",
      "ðŸ” Agent: [Calling retrieval tool...]\n",
      "ðŸ¤– Agent: There are 20 standard amino acids that are commonly found in proteins. These amino acids are classified based on their side chains, which can be nonpolar, polar, or charged. \n",
      "\n",
      "In addition to these 20 standard amino acids, there are also a few rare amino acids that can be incorporated into proteins during specific conditions or in certain organisms, but they are not part of the standard genetic code. \n",
      "\n",
      "If you need further details about specific amino acids or their functions, feel free to ask!\n",
      "\n",
      "ðŸ“Š Decision: USED RETRIEVAL\n",
      "======================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Follow-up\n",
    "query_agent(\"How many of them exist?\", thread_id=\"followup_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "9506e7a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "ðŸ‘¤ User: Explain the relationship between DNA, proteins, and amino acids\n",
      "======================================================================\n",
      "\n",
      "ðŸ” Agent: [Calling retrieval tool...]\n",
      "ðŸ¤– Agent: The relationship between DNA, proteins, and amino acids is fundamental to the processes of genetics and biochemistry. Hereâ€™s a breakdown of how these components interact:\n",
      "\n",
      "1. **DNA (Deoxyribonucleic Acid)**: DNA is the genetic material that contains the instructions for building proteins. It is composed of sequences of nucleotides, each consisting of a sugar, a phosphate group, and a nitrogenous base. The sequence of these bases encodes the information necessary for the synthesis of proteins.\n",
      "\n",
      "2. **Proteins**: Proteins are large, complex molecules that play many critical roles in biological systems. They are made up of long chains of amino acids, which are linked together by peptide bonds. The specific sequence of amino acids in a protein is determined by the corresponding sequence of nucleotides in the DNA. \n",
      "\n",
      "3. **Amino Acids**: Amino acids are the building blocks of proteins. There are 20 different amino acids that can be combined in various sequences to form proteins. Each amino acid has a specific side chain that determines its properties and role in the protein structure. The genetic code in DNA specifies which amino acids are to be used in protein synthesis.\n",
      "\n",
      "The process of protein synthesis involves two main steps:\n",
      "- **Transcription**: The DNA sequence of a gene is transcribed into messenger RNA (mRNA). This mRNA carries the genetic information from the nucleus to the ribosome, where proteins are synthesized.\n",
      "- **Translation**: The mRNA is translated into a specific sequence of amino acids, forming a polypeptide chain that folds into a functional protein. Each set of three nucleotides (codon) in the mRNA corresponds to a specific amino acid.\n",
      "\n",
      "In summary, DNA provides the blueprint for proteins, proteins are made up of amino acids, and the sequence of amino acids is dictated by the sequence of nucleotides in DNA. This relationship is crucial for the functioning of cells and the expression of genetic traits.\n",
      "\n",
      "ðŸ“Š Decision: USED RETRIEVAL\n",
      "======================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query_agent(\"Explain the relationship between DNA, proteins, and amino acids\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "eddac914",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Traditional RAG function defined\n"
     ]
    }
   ],
   "source": [
    "def traditional_rag(query: str) -> str:\n",
    "    \"\"\"\n",
    "    Traditional RAG: ALWAYS retrieve.\n",
    "    \"\"\"\n",
    "    # Always retrieve\n",
    "    docs = vectorstore.similarity_search(query, k=3)\n",
    "    context = \"\\n\\n\".join([doc.page_content for doc in docs])\n",
    "    \n",
    "    # Generate answer\n",
    "    prompt = f\"\"\"Based on this context, answer the question.\n",
    "    \n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question: {query}\n",
    "\n",
    "Answer:\"\"\"\n",
    "    \n",
    "    response = llm.invoke([HumanMessage(content=prompt)])\n",
    "    return response.content\n",
    "\n",
    "print(\"âœ… Traditional RAG function defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "86758992",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "Query: Hello!\n",
      "======================================================================\n",
      "\n",
      "ðŸ”µ TRADITIONAL RAG (always retrieves):\n",
      "Answer: Hello! How can I assist you today?...\n",
      "Decision: ALWAYS RETRIEVED\n",
      "\n",
      "ðŸŸ¢ AGENTIC RAG (agent decides):\n",
      "Answer: I'm here to help you find information. What do you need assistance with?...\n",
      "Decision: ANSWERED DIRECTLY\n",
      "\n",
      "======================================================================\n",
      "\n",
      "\n",
      "======================================================================\n",
      "Query: What is 2+2?\n",
      "======================================================================\n",
      "\n",
      "ðŸ”µ TRADITIONAL RAG (always retrieves):\n",
      "Answer: 2 + 2 = 4....\n",
      "Decision: ALWAYS RETRIEVED\n",
      "\n",
      "ðŸŸ¢ AGENTIC RAG (agent decides):\n",
      "Answer: I can't assist with simple math questions. If you have another type of inquiry, feel free to ask!...\n",
      "Decision: ANSWERED DIRECTLY\n",
      "\n",
      "======================================================================\n",
      "\n",
      "\n",
      "======================================================================\n",
      "Query: What is biosynthesis?\n",
      "======================================================================\n",
      "\n",
      "ðŸ”µ TRADITIONAL RAG (always retrieves):\n",
      "Answer: Biosynthesis is the process by which living organisms produce complex molecules from simpler ones. It typically involves a series of enzymatic reactio...\n",
      "Decision: ALWAYS RETRIEVED\n",
      "\n",
      "ðŸŸ¢ AGENTIC RAG (agent decides):\n",
      "Answer: Biosynthesis is the process by which living organisms produce complex compounds from simpler ones, utilizing energy and various enzymatic reactions. T...\n",
      "Decision: RETRIEVED\n",
      "\n",
      "======================================================================\n",
      "\n",
      "\n",
      "======================================================================\n",
      "Query: Explain amino acid metabolism\n",
      "======================================================================\n",
      "\n",
      "ðŸ”µ TRADITIONAL RAG (always retrieves):\n",
      "Answer: Amino acid metabolism involves a series of biochemical processes that manage the synthesis, breakdown, and utilization of amino acids in the body. Ami...\n",
      "Decision: ALWAYS RETRIEVED\n",
      "\n",
      "ðŸŸ¢ AGENTIC RAG (agent decides):\n",
      "Answer: Amino acid metabolism refers to the biochemical processes involved in the synthesis and degradation of amino acids, which are the building blocks of p...\n",
      "Decision: RETRIEVED\n",
      "\n",
      "======================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_queries = [\n",
    "    \"Hello!\",                                          # Should NOT need retrieval\n",
    "    \"What is 2+2?\",                                   # Should NOT need retrieval\n",
    "    \"What is biosynthesis?\",                          # SHOULD need retrieval\n",
    "    \"Explain amino acid metabolism\",                  # SHOULD need retrieval\n",
    "]\n",
    "\n",
    "for query in test_queries:\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"Query: {query}\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    print(\"\\nðŸ”µ TRADITIONAL RAG (always retrieves):\")\n",
    "    trad_answer = traditional_rag(query)\n",
    "    print(f\"Answer: {trad_answer[:150]}...\")\n",
    "    print(\"Decision: ALWAYS RETRIEVED\")\n",
    "    \n",
    "    print(\"\\nðŸŸ¢ AGENTIC RAG (agent decides):\")\n",
    "    # Test with agentic approach\n",
    "    result = agent.invoke(\n",
    "        {\"messages\": [HumanMessage(content=query)]},\n",
    "        config={\"configurable\": {\"thread_id\": \"comparison_test\"}}\n",
    "    )\n",
    "    \n",
    "    # Check if retrieval was used\n",
    "    used_retrieval = any(\n",
    "        isinstance(msg, AIMessage) and msg.tool_calls \n",
    "        for msg in result[\"messages\"]\n",
    "    )\n",
    "    \n",
    "    final_answer = result[\"messages\"][-1].content\n",
    "    print(f\"Answer: {final_answer[:150]}...\")\n",
    "    print(f\"Decision: {'RETRIEVED' if used_retrieval else 'ANSWERED DIRECTLY'}\")\n",
    "    \n",
    "    print(f\"\\n{'='*70}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3cc6b39",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".allenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
